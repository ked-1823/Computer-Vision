{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24bd059d-9532-4fe4-b42d-81091d2e3663",
   "metadata": {},
   "source": [
    "# **Real-Time Face, Eye & Smile Detection with Screenshot Capture**\n",
    "\n",
    "## **Overview**\n",
    "This project detects **faces, eyes, and smiles in real-time** using a webcam feed.  \n",
    "It uses **OpenCV's Haar cascade classifiers** to detect facial features, overlay bounding boxes, display detection messages, and capture screenshots when the user presses a key.  \n",
    "\n",
    "It demonstrates **grayscale conversion, region-of-interest extraction, dynamic overlays, and keyboard interaction** in a practical, real-time computer vision application.\n",
    "\n",
    "---\n",
    "\n",
    "## **Features**\n",
    "- **Face Detection:** Highlights detected faces with **green rectangles**.  \n",
    "- **Eye Detection:** Highlights detected eyes inside each face with **blue rectangles**.  \n",
    "- **Smile Detection:** Highlights detected smiles inside each face with **red rectangles**.  \n",
    "- **Text Overlay:** Displays **\"face detected\"**, **\"eye detected\"**, and **\"smile detected\"** above detections.  \n",
    "- **Screenshot Capture:** Press **`s`** to save the current frame with all detections.  \n",
    "- **Quit Program:** Press **`q`** to exit the webcam feed safely.  \n",
    "\n",
    "---\n",
    "\n",
    "## **How It Works**\n",
    "1. **Load Haar Cascade Classifiers**  \n",
    "   Pretrained XML classifiers for **faces, eyes, and smiles** are loaded. Haar cascades work on **grayscale images**, so frames are converted before detection.\n",
    "\n",
    "2. **Capture Webcam Frames**  \n",
    "   The program continuously reads frames from the webcam to create a **real-time video feed**.\n",
    "\n",
    "3. **Convert Frames to Grayscale**  \n",
    "   Each frame is converted to grayscale to match the format expected by Haar cascades.\n",
    "\n",
    "4. **Detect Faces**  \n",
    "   The face classifier scans the grayscale frame and identifies **rectangular regions** where faces are detected.  \n",
    "   - Green rectangles are drawn around faces.  \n",
    "   - **\"face detected\"** text is displayed above each face.\n",
    "\n",
    "5. **Detect Eyes Within Each Face**  \n",
    "   For each detected face, a **Region of Interest (ROI)** is defined, and the eye classifier detects eyes within that ROI.  \n",
    "   - Blue rectangles are drawn around eyes.  \n",
    "   - **\"eye detected\"** text is displayed above the face.\n",
    "\n",
    "6. **Detect Smiles Within Each Face**  \n",
    "   The smile classifier scans the same ROI to detect smiles.  \n",
    "   - Red rectangles are drawn around smiles.  \n",
    "   - **\"smile detected\"** text is displayed slightly above or near the face.\n",
    "\n",
    "7. **Keyboard Interaction**  \n",
    "   - Press **`s`** → saves the current frame as a screenshot.  \n",
    "   - Press **`q`** → exits the program gracefully and releases the webcam.\n",
    "\n",
    "8. **Save Screenshots**  \n",
    "   Screenshots are saved in the **current working directory** with sequential filenames, and the absolute path is printed for reference.\n",
    "\n",
    "---\n",
    "\n",
    "## **How to Use**\n",
    "1. Run the notebook or script on a computer with a webcam.  \n",
    "2. Position your face in front of the camera.  \n",
    "3. Green rectangles appear around faces, blue rectangles around eyes, and red rectangles around smiles.  \n",
    "4. Press **`s`** to save a screenshot.  \n",
    "5. Press **`q`** to quit the program.\n",
    "\n",
    "---\n",
    "\n",
    "## **Learning Outcomes**\n",
    "- Understand **Haar cascade classifiers** for **faces, eyes, and smiles**.  \n",
    "- Learn **grayscale conversion** and **ROI extraction** for nested feature detection.  \n",
    "- Implement **dynamic overlays** for multiple facial features simultaneously.  \n",
    "- Handle **keyboard interaction** to capture screenshots and control program flow.  \n",
    "- Gain hands-on experience with **real-time computer vision applications** in OpenCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f36261b-5313-460b-a8bf-5c4cdc14f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "eye_cas=cv2.CascadeClassifier(r\"C:\\Users\\manek\\Downloads\\haarcascade_eye.xml\")\n",
    "face_cas=cv2.CascadeClassifier(r\"C:\\Users\\manek\\Downloads\\haarcascade_frontalface_default.xml\")\n",
    "smile_cas=cv2.CascadeClassifier(r\"C:\\Users\\manek\\Downloads\\haarcascade_smile.xml\")\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "frame_count=0\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cas.detectMultiScale(gray,1.1,5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y), (x+w,y+h),(0,255,0),2)\n",
    "        if len(faces)>=1:\n",
    "            cv2.putText(frame,'face detected',(x,y-20),cv2.FONT_HERSHEY_DUPLEX,0.7,(255,0,0),2)\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_color=frame[y:y+h,x:x+w]\n",
    "        eye=eye_cas.detectMultiScale(roi_gray,1.05,30)\n",
    "        smile=smile_cas.detectMultiScale(roi_gray,1.05,30)\n",
    "        for (ex,ey,ew,eh) in eye:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,0,0),3)\n",
    "            if len(eye)>=1:\n",
    "                cv2.putText(frame,'eye detected',(x,y-40),cv2.FONT_HERSHEY_DUPLEX,0.7,(255,200,0),1)\n",
    "        for (sx,sy,sw,sh) in smile:\n",
    "            cv2.rectangle(roi_color,(sx,sy),(sx+sw,sy+sh),(255,0,0),1)\n",
    "            if len(smile)>1:\n",
    "                cv2.putText(frame,'smile detected',(x,y-5),cv2.FONT_HERSHEY_DUPLEX,0.7,(255,0,200),1)\n",
    "        \n",
    "    cv2.imshow('face detection',frame)\n",
    "    key=cv2.waitKey(1) & 0xFF\n",
    "    if key==ord(\"q\"):\n",
    "        break\n",
    "    if key==ord('s'):\n",
    "        filename=f'ss_{frame_count}.png'\n",
    "        cv2.imwrite(filename,frame)\n",
    "        print('screenshot saved')\n",
    "        frame_count+=1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e92eaf46-7959-45f6-b58e-a7cce776ee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot saved at: C:\\Users\\manek\\ss_0.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = f'ss_{frame_count}.png'\n",
    "cv2.imwrite(filename, frame)\n",
    "print(\"Screenshot saved at:\", os.path.abspath(filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8de43-7a5a-4556-a28f-098581ebc62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
